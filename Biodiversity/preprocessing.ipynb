{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_info import *\n",
    "from tools import *\n",
    "from plot import *\n",
    "from ntpath import join\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_root):\n",
    "\n",
    "    datadir = join(data_root, 'GIMMS3g_NDVI')\n",
    "\n",
    "    clean(datadir)\n",
    "    resample_merge(datadir)\n",
    "    monthly_compose(datadir, method='max')\n",
    "    deseason_detrend(datadir)\n",
    "    Month_to_daily(datadir)\n",
    "    HANTS().run(datadir)\n",
    "    growing_season_mask_monthly(datadir)\n",
    "\n",
    "def calculate_growing_season(growing_season_mask):\n",
    "    \"\"\"\n",
    "    计算生长季开始时间、结束时间、长度\n",
    "\n",
    "    \"\"\"\n",
    "    growing_season_start = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "    growing_season_end = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "    growing_season_lenth = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(growing_season_mask.lat.values):\n",
    "        for lon in growing_season_mask.lon.values:\n",
    "            # 提取单个像元的温度和掩码\n",
    "            pixel_growing_season_mask = growing_season_mask.sel(lat=lat, lon=lon)\n",
    "            \n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_growing_season_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "            \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_growing_season_mask.time) and pixel_growing_season_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    start_time = pixel_growing_season_mask.time[start_idx].values  # 获取生长季开始时间  \n",
    "                    start_month_of_year  = pd.to_datetime(start_time).month\n",
    "                    end_time = pixel_growing_season_mask.time[end_idx - 1].values  # 获取生长季结束时间\n",
    "                    end_month_of_year  = pd.to_datetime(end_time).month\n",
    "                    # 转换为 pandas Timestamp\n",
    "                    start_timestamp = pd.to_datetime(start_time)\n",
    "                    end_timestamp = pd.to_datetime(end_time)\n",
    "                    # 计算月份差异\n",
    "                    length_months = (end_timestamp.year - start_timestamp.year) * 12 + end_timestamp.month - start_timestamp.month + 1\n",
    "                    # length = np.datetime64(end_time) - np.datetime64(start_time)# 获取生长季长度\n",
    "                    # length_days = length.astype('timedelta64[D]').astype(int) + 1  \n",
    "                    growing_season_start.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = start_month_of_year\n",
    "                    growing_season_end.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = end_month_of_year\n",
    "                    growing_season_lenth.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = length_months\n",
    "\n",
    "                  \n",
    "    growing_season_start.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_start.nc4')\n",
    "    growing_season_end.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_end.nc4')\n",
    "    growing_season_lenth.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_lenth.nc4')        \n",
    "\n",
    "    return growing_season_start, growing_season_end, growing_season_lenth\n",
    "\n",
    "def drop_consecutive_drought(drought_mask):\n",
    "    \"\"\"\n",
    "    去除两年内连续发生的干旱\n",
    "\n",
    "    \"\"\"\n",
    "    drop_nyear_drought = drought_mask.copy()\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drop_nyear_drought.lat.values):\n",
    "        for lon in drop_nyear_drought.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for i, start_idx in enumerate(region_starts):\n",
    "                    if i + 1 < len(region_starts):\n",
    "                        months_between = region_starts[i+1] - region_starts[i]\n",
    "                        if months_between <=24:\n",
    "                            next_end_idx = region_starts[i+1] +1\n",
    "                            while next_end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[next_end_idx] == 1:\n",
    "                                next_end_idx += 1  # 找到连续区间的结束索引\n",
    "                            region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(next_end_idx)))  \n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time}] = np.nan\n",
    "                                                       \n",
    "    return  drop_nyear_drought \n",
    "\n",
    "def drop_consecutive_all_drought(drought_mask, another_drought_mask):\n",
    "    \"\"\"\n",
    "    去除两年内连续发生的干旱\n",
    "\n",
    "    \"\"\"\n",
    "    drop_nyear_drought = drought_mask.copy()\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drop_nyear_drought.lat.values):\n",
    "        for lon in drop_nyear_drought.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "            pixel_another_drought_mask = another_drought_mask.sel(lat=lat, lon=lon)\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for i, start_idx in enumerate(region_starts):\n",
    "                    if i + 1 < len(region_starts):\n",
    "                        months_between = region_starts[i+1] - region_starts[i]\n",
    "                        if months_between <=24:\n",
    "                            next_end_idx = region_starts[i+1] +1\n",
    "                            while next_end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[next_end_idx] == 1:\n",
    "                                next_end_idx += 1  # 找到连续区间的结束索引\n",
    "                            region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(next_end_idx)))  \n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time}] = np.nan\n",
    "\n",
    "                    if i < len(region_starts):\n",
    "                        two_years_later = pd.to_datetime(pixel_drought_mask.time[start_idx].values) + pd.DateOffset(years=2) # 干旱开始后的两年\n",
    "                        if two_years_later <= (pixel_another_drought_mask.time[-1].values):        \n",
    "                            two_years_another_drought = pixel_another_drought_mask.sel(time=slice(pixel_drought_mask.time[start_idx].values, two_years_later))\n",
    "                        else:\n",
    "                            two_years_another_drought = pixel_another_drought_mask.sel(time=slice(pixel_drought_mask.time[start_idx].values, pixel_another_drought_mask.time[-1].values))\n",
    "                        if (two_years_another_drought == 1).any():\n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': two_years_another_drought.time[0]}] = np.nan\n",
    "    return  drop_nyear_drought \n",
    "\n",
    "def statistic_drought_times(drough_mask):\n",
    "    \"\"\"\n",
    "    计算干旱次数\n",
    "\n",
    "    \"\"\"\n",
    "    drought_times = xr.full_like(drough_mask, np.nan)  \n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drough_mask.lat.values):\n",
    "        for lon in drough_mask.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drough_mask.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(end_idx)))  \n",
    "                    drought_times.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time[0]}] = 1\n",
    "                                                       \n",
    "    return  drought_times \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Deseason_detrend\\deseason_detrend.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Result\\drought_frequency.nc')\n",
    "# ds1=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc')\n",
    "# ds = xr.open_dataset('E:/PHD_Project/Data/GIMMS3g_NDVI/Resample_merge/ndvi3g_geo_v1_2_2021_0712.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Month_to_daily\\1988.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Hants_daily\\2021.nc4')\n",
    "# ds1=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Month_to_daily\\2021.nc4')\n",
    "# xr.open_mfdataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Hants_daily\\*.nc4', concat_dim='time', combine='nested' )\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\growing_season_mask_monthly.nc4')\n",
    "# growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\growing_season_mask_monthly.nc4').ndvi\n",
    "# growing_season_mask.isel(time=12).plot()\n",
    "# growing_season_mask.sel(time=slice('2010-01-01', '2012-01-01')).sel(lon=100, lat=60 , method='nearest').plot()\n",
    "# growing_season_mask.sel(time=slice('2010-01-01', '2013-01-01')).sel(lon=-50, lat=0 , method='nearest').plot()\n",
    "# growing_season_mask.sel(time=slice('1982-01-01', '1986-01-01')).sel(lon=-50, lat=-20 , method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_GIMMS = join(data_root, 'GIMMS3g_NDVI')\n",
    "datadir_SPEI = join(data_root, 'SPEI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生长季开始，结束，长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "growing_season_start, growing_season_end, growing_season_lenth=calculate_growing_season(growing_season_mask)\n",
    "growing_season_start=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_start.nc4')\n",
    "growing_season_end=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_end.nc4')\n",
    "growing_season_lenth=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_lenth.nc4')\n",
    "def filter_multigrowing_season(ds):\n",
    "    \n",
    "    growing_season_mask = (ds > 0)\n",
    "    season_starts_per_year = growing_season_mask.sum(dim='time', skipna=True)\n",
    "    return ds.where(season_starts_per_year <=1)\n",
    "\n",
    "# 将这些像元在原数据中设置为NaN\n",
    "growing_season_start_new = growing_season_start.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_end_new = growing_season_end.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_lenth_new = growing_season_lenth.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_start_mean =growing_season_start_new.ndvi.mean(dim='time')\n",
    "growing_season_end_mean =growing_season_end_new.ndvi.mean(dim='time')\n",
    "growing_season_lenth_mean =growing_season_lenth_new.ndvi.mean(dim='time')\n",
    "statistics_2d(growing_season_start_mean)\n",
    "statistics_2d(growing_season_end_mean)\n",
    "statistics_2d(growing_season_lenth_mean)\n",
    "plot_spei2d(growing_season_start_mean, cmap= 'viridis')\n",
    "plot_spei2d(growing_season_end_mean, cmap= 'viridis')\n",
    "plot_spei2d(growing_season_lenth_mean, cmap= 'YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算并统计四种干旱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\normal_drought_times.nc').ndvi\n",
    "extreme_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\extreme_drought_times.nc').ndvi\n",
    "normal_hot_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\normal_hot_drought_times.nc').ndvi\n",
    "extreme_hot_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\extreme_hot_drought_times.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_times_sum = normal_drought_times.sum(dim='time')\n",
    "extreme_drought_times_sum = extreme_drought_times.sum(dim='time')\n",
    "normal_hot_drought_times_sum = normal_hot_drought_times.sum(dim='time')\n",
    "extreme_hot_drought_times_sum = extreme_hot_drought_times.sum(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(normal_drought_times_sum.where(normal_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(extreme_drought_times_sum.where(extreme_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(normal_hot_drought_times_sum.where(normal_hot_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(extreme_hot_drought_times_sum.where(extreme_hot_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(normal_drought_times_sum.where(normal_drought_times_sum>0), cmap='hot', vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(extreme_drought_times_sum.where(extreme_drought_times_sum>0), cmap='hot', vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(normal_hot_drought_times_sum.where(normal_hot_drought_times_sum>0), cmap='hot', vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(extreme_hot_drought_times_sum.where(extreme_hot_drought_times_sum>0), cmap='hot', vmax =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc').spei\n",
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "tmp=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Source\\cru_ts4.07.1901.2022.tmp.dat.nc').tmp\n",
    "hot_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Hot_drought_tmp\\hot_mask.nc').tmp\n",
    "# 按月重采样到每月开始, 将时间对齐\n",
    "spei = spei.resample(time='MS').mean()  # 'MS'表示每月的开始，mean()是一种聚合方法，你可以根据需要选择合适的聚合方法\n",
    "growing_season_mask = growing_season_mask.resample(time='MS').mean()\n",
    "# 截取ndvi同等时间段\n",
    "tmp=tmp.resample(time='MS').mean().sel(time=growing_season_mask.time)\n",
    "spei = spei.sel(time=growing_season_mask.time)\n",
    "#筛选干旱并提取生长季干旱\n",
    "normal_hot_drought_mask = growing_season_mask.where((spei < -0.5) & (spei > -1.5) & (hot_mask == 1))\n",
    "extreme_hot_drought_mask = growing_season_mask.where((spei <= -1.5) & (hot_mask == 1))\n",
    "normal_drought_mask = growing_season_mask.where((spei < -0.5) & (spei > -1.5) & (normal_hot_drought_mask != 1))\n",
    "extreme_drought_mask = growing_season_mask.where((spei <= -1.5) & (extreme_hot_drought_mask != 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_drought(drought_types, out_fname_list):\n",
    "\n",
    "    results_droped_drought=[]\n",
    "    results_drought_times=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "\n",
    "        droped_drought=drop_consecutive_drought(drought_types[i])\n",
    "        \n",
    "        drought_times=statistic_drought_times(droped_drought)\n",
    "\n",
    "        results_droped_drought.append(droped_drought)\n",
    "        results_drought_times.append(drought_times)\n",
    "\n",
    "        droped_drought.to_netcdf(rf'E:\\PHD_Project\\Results\\Drought_types\\{out_fname_list[i]}_droped.nc') \n",
    "        drought_times.to_netcdf(rf'E:\\PHD_Project\\Results\\Drought_types\\{out_fname_list[i]}_times.nc') \n",
    "    \n",
    "    return results_droped_drought, results_drought_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_hot_drought_mask, extreme_hot_drought_mask, normal_drought_mask, extreme_drought_mask]\n",
    "out_fname_list=['normal_hot_drought', 'extreme_hot_drought', 'normal_drought', 'extreme_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_drought, drought_times=caculate_drought(drought_types, out_fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据干旱强度提取、划分高温干旱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_one_month_slight_drought(spei):\n",
    "\n",
    "    condition = (spei<= -0.5) & (spei>= -0.55)\n",
    "\n",
    "    # 遍历每个空间位置\n",
    "    for lat in tqdm(spei.lat, desc='Processing Latitude'):\n",
    "        for lon in spei.lon:\n",
    "            # 提取该位置的时间序列\n",
    "            pixel_spei = condition.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_spei == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_spei.time) and pixel_spei[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    if end_idx - start_idx <= 1:\n",
    "                        region_spei = pixel_spei.isel(time=slice(int(start_idx), int(end_idx))) \n",
    "                    \n",
    "                        spei.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = np.nan\n",
    "                    \n",
    "    return spei\n",
    "\n",
    "def caculate_new_drought(drought_types, out_fname_list):\n",
    "\n",
    "    results_droped_drought=[]\n",
    "    results_drought_times=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "        if i == 0:\n",
    "            droped_drought=drop_consecutive_all_drought(drought_types[i], drought_types[i+1])\n",
    "            drought_times=statistic_drought_times(droped_drought)\n",
    "            results_droped_drought.append(droped_drought)\n",
    "            results_drought_times.append(drought_times)\n",
    "        if i == 1:\n",
    "            droped_drought=drop_consecutive_all_drought(drought_types[i], drought_types[i-1])\n",
    "            drought_times=statistic_drought_times(droped_drought)\n",
    "            results_droped_drought.append(droped_drought)\n",
    "            results_drought_times.append(drought_times)\n",
    "            \n",
    "        droped_drought.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_types\\{out_fname_list[i]}_droped.nc') \n",
    "        drought_times.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_types\\{out_fname_list[i]}_times.nc') \n",
    "    \n",
    "    return results_droped_drought, results_drought_times\n",
    "\n",
    "def drought_intensity_duration(drought_mask, spei ):\n",
    "\n",
    "   \n",
    "    drought_intensity = xr.full_like(drought_mask, np.nan) \n",
    "    drought_duration = xr.full_like(drought_mask, np.nan) \n",
    "\n",
    "    # 遍历每个空间位置\n",
    "    for lat in tqdm(drought_mask.lat, desc='Processing Latitude'):\n",
    "        for lon in drought_mask.lon:\n",
    "            # 提取该位置的时间序列\n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "            pixel_spei = spei.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    region_spei = pixel_spei.isel(time=slice(int(start_idx), int(end_idx)))  \n",
    "                    result_drought_intensity = -(region_spei.sum())\n",
    "                    result_drought_duration = end_idx - start_idx + 1\n",
    "                    drought_intensity.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = result_drought_intensity\n",
    "                    drought_duration.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = result_drought_duration\n",
    "\n",
    "    return drought_intensity, drought_duration\n",
    "\n",
    "def caculate_intensity_durantion(drought_types, out_fname_list ,spei):\n",
    "\n",
    "    results_intensity=[]\n",
    "    results_duration=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "\n",
    "        intensity, duration= drought_intensity_duration(drought_types[i], spei)\n",
    "\n",
    "        results_intensity.append(intensity)\n",
    "        results_duration.append(duration)\n",
    "\n",
    "        intensity.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\{out_fname_list[i]}_intensity.nc') \n",
    "        duration.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\{out_fname_list[i]}_duration.nc') \n",
    "    \n",
    "    return results_intensity, results_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_spei= drop_one_month_slight_drought(spei)\n",
    "droped_spei.to_netcdf(rf'E:\\PHD_Project\\Data\\SPEI\\Result\\droped_spei.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc').spei\n",
    "droped_spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Result\\droped_spei.nc').spei\n",
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "tmp=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Source\\cru_ts4.07.1901.2022.tmp.dat.nc').tmp\n",
    "hot_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Hot_drought_tmp\\hot_mask.nc').tmp\n",
    "# 按月重采样到每月开始, 将时间对齐\n",
    "spei = spei.resample(time='MS').mean()  # 'MS'表示每月的开始，mean()是一种聚合方法，你可以根据需要选择合适的聚合方法\n",
    "growing_season_mask = growing_season_mask.resample(time='MS').mean()\n",
    "# 截取ndvi同等时间段\n",
    "tmp=tmp.resample(time='MS').mean().sel(time=growing_season_mask.time)\n",
    "spei = spei.sel(time=growing_season_mask.time)\n",
    "#筛选干旱并提取生长季干旱\n",
    "hot_drought_mask = growing_season_mask.where((droped_spei < -0.5) & (hot_mask == 1))\n",
    "normal_drought_mask = growing_season_mask.where((droped_spei < -0.5) & (hot_drought_mask != 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_drought_mask, hot_drought_mask]\n",
    "out_fname_list=['normal_drought', 'hot_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_drought, drought_times=caculate_new_drought(drought_types, out_fname_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_droped=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_types\\normal_drought_droped.nc').ndvi\n",
    "hot_drought_droped=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_types\\hot_drought_droped.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d((drought_times[0].sum(dim= 'time').where(drought_times[0].sum(dim= 'time')>0)), cmap= global_cmap_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(drought_times[1].sum(dim= 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_drought_droped, hot_drought_droped]\n",
    "out_fname_list=['normal_drought', 'hot_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_intensity, results_duration=caculate_intensity_durantion(drought_types, out_fname_list, spei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_intensity=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\hot_drought_intensity.nc').ndvi\n",
    "hot_drought_duration=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\hot_drought_duration.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_intensity.mean(dim= 'time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_duration.mean(dim= 'time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique((hot_drought_intensity.sel(time=slice('1982-01-01', '2022-01-01')).sel(lon=-50, lat=-20 , method='nearest')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取相应像元的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot_drought_duration=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\hot_drought_duration.nc').ndvi\n",
    "# hot_drought_intensity=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\hot_drought_intensity.nc').ndvi\n",
    "normal_drought_duration=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\normal_drought_duration.nc').ndvi\n",
    "normal_drought_intensity=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\normal_drought_intensity.nc').ndvi\n",
    "standard_ds = xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\hot_drought_resilience.nc').ndvi\n",
    "# 获取基准数据的坐标\n",
    "target_coords = standard_ds.drop_vars('month').coords\n",
    "# 重采样到0.08\n",
    "# hot_drought_duration = hot_drought_duration.interp(coords=target_coords, method='nearest')\n",
    "# hot_drought_intensity = hot_drought_intensity.interp(coords=target_coords, method='nearest')\n",
    "normal_drought_duration = normal_drought_duration.interp(coords=target_coords, method='nearest')\n",
    "normal_drought_intensity = normal_drought_intensity.interp(coords=target_coords, method='nearest')\n",
    "# hot_drought_duration = hot_drought_duration.astype('float32')\n",
    "# hot_drought_intensity = hot_drought_intensity.astype('float32')\n",
    "normal_drought_duration = normal_drought_duration.astype('float32')\n",
    "normal_drought_intensity = normal_drought_intensity.astype('float32')\n",
    "# hot_drought_duration.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "# hot_drought_intensity.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "normal_drought_duration.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "normal_drought_intensity.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重采样为0.08度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_008(resampled_dataset, outdir):\n",
    "    target_ds= xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\normal_drought_resilience.nc').ndvi\n",
    "    target_lon = np.append(target_ds.lon.values,target_ds.lon.values[-1]+0.08)-0.04\n",
    "    target_lat = np.append(target_ds.lat.values, target_ds.lat.values[-1]-0.08)+0.04\n",
    "    # 对纬度进行分组和聚合\n",
    "    aa = resampled_dataset.groupby_bins(\"x\", bins=target_lon, labels=target_ds.lon.values).mean(skipna = True)\n",
    "    bb= aa.groupby_bins(\"y\", bins=target_lat[::-1], labels=target_ds.lat.values[::-1]).mean(skipna = True)\n",
    "    bb.rio.set_spatial_dims(x_dim='x_bins', y_dim='y_bins', inplace=True)\n",
    "    bb.rio.write_nodata(np.nan, inplace=True)\n",
    "    bb.rio.to_raster(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重采样WorldClim数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names= os.listdir(r'G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio')\n",
    "for filename in tqdm(file_names):\n",
    "    ds = rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio\\{filename}', masked=True)\n",
    "    outdir = fr'G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio_0.08\\{filename}'\n",
    "    resample_008(ds, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重采样soilgrid数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dirs = os.listdir(r'G:\\PHD_Project\\Data\\SoilGrid_v2.0')\n",
    "for file_dir in tqdm(file_dirs):\n",
    "    file_path = os.path.join(r'G:\\PHD_Project\\Data\\SoilGrid_v2.0', file_dir)\n",
    "    file_names = os.listdir(file_path)\n",
    "    if len(file_names)>2:\n",
    "        ds1=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_0-5cm_mean_1000.tif', masked=True)\n",
    "        ds1=ds1.rio.reproject(\"EPSG:4326\")\n",
    "        ds2=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_5-15cm_mean_1000.tif', masked=True)\n",
    "        ds2=ds2.rio.reproject(\"EPSG:4326\")\n",
    "        ds3=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_15-30cm_mean_1000.tif', masked=True)\n",
    "        ds3=ds3.rio.reproject(\"EPSG:4326\")\n",
    "        ds4=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_30-60cm_mean_1000.tif', masked=True)\n",
    "        ds4=ds4.rio.reproject(\"EPSG:4326\")\n",
    "        ds5=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_60-100cm_mean_1000.tif', masked=True)\n",
    "        ds5=ds5.rio.reproject(\"EPSG:4326\")\n",
    "        ds6=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_100-200cm_mean_1000.tif', masked=True)\n",
    "        ds6=ds6.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie1=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_0-5cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie1=bulk_densitie1.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie2=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_5-15cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie2=bulk_densitie2.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie3=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_15-30cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie3=bulk_densitie3.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie4=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_30-60cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie4=bulk_densitie4.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie5=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_60-100cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie5=bulk_densitie5.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie6=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\bdod\\bdod_100-200cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie6=bulk_densitie6.rio.reproject(\"EPSG:4326\")\n",
    "        weight1 = bulk_densitie1 * 5\n",
    "        weight2 = bulk_densitie2 * 10\n",
    "        weight3 = bulk_densitie3 * 15\n",
    "        weight4 = bulk_densitie4 * 30\n",
    "        weight5 = bulk_densitie5 * 40\n",
    "        weight6 = bulk_densitie6 * 100\n",
    "        layer_30 = (ds1*weight1 + ds2*weight2 + ds3*weight3)/(weight1 + weight2 + weight3)\n",
    "        layer_100 = (ds4*weight4 + ds5*weight5)/(weight4 + weight5)\n",
    "        layer_200 = ds6\n",
    "        outdir1 = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_0-30cm_mean.tif'\n",
    "        outdir2 = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_30-100cm_mean.tif'\n",
    "        outdir3 = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_100-200cm_mean.tif'\n",
    "        ouput_path = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}'\n",
    "        mk_dir(ouput_path)\n",
    "        resample_008(layer_30, outdir1)\n",
    "        resample_008(layer_100, outdir2)\n",
    "        resample_008(layer_200, outdir3)\n",
    "    else:\n",
    "        ds = rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_0-30cm_mean_1000.tif', masked=True)\n",
    "        ds=ds.rio.reproject(\"EPSG:4326\")\n",
    "        ouput_path = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}'\n",
    "        mk_dir(ouput_path)\n",
    "        outdir = fr'G:\\PHD_Project\\Data\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_0-30cm_mean.tif'\n",
    "        resample_008(ds, outdir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dirs=['nitrogen']\n",
    "for file_dir in tqdm(file_dirs):\n",
    "    file_path = os.path.join(r'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0', file_dir)\n",
    "    file_names = os.listdir(file_path)\n",
    "    if len(file_names)>2:\n",
    "        ds1=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_0-5cm_mean_1000.tif', masked=True)\n",
    "        ds1=ds1.rio.reproject(\"EPSG:4326\")\n",
    "        ds2=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_5-15cm_mean_1000.tif', masked=True)\n",
    "        ds2=ds2.rio.reproject(\"EPSG:4326\")\n",
    "        ds3=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_15-30cm_mean_1000.tif', masked=True)\n",
    "        ds3=ds3.rio.reproject(\"EPSG:4326\")\n",
    "        ds4=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_30-60cm_mean_1000.tif', masked=True)\n",
    "        ds4=ds4.rio.reproject(\"EPSG:4326\")\n",
    "        ds5=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_60-100cm_mean_1000.tif', masked=True)\n",
    "        ds5=ds5.rio.reproject(\"EPSG:4326\")\n",
    "        ds6=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\{file_dir}\\{file_dir}_100-200cm_mean_1000.tif', masked=True)\n",
    "        ds6=ds6.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie1=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_0-5cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie1=bulk_densitie1.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie2=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_5-15cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie2=bulk_densitie2.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie3=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_15-30cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie3=bulk_densitie3.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie4=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_30-60cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie4=bulk_densitie4.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie5=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_60-100cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie5=bulk_densitie5.rio.reproject(\"EPSG:4326\")\n",
    "        bulk_densitie6=rxr.open_rasterio(fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_v2.0\\bdod\\bdod_100-200cm_mean_1000.tif', masked=True)\n",
    "        bulk_densitie6=bulk_densitie6.rio.reproject(\"EPSG:4326\")\n",
    "        weight1 = bulk_densitie1 * 5\n",
    "        weight2 = bulk_densitie2 * 10\n",
    "        weight3 = bulk_densitie3 * 15\n",
    "        weight4 = bulk_densitie4 * 30\n",
    "        weight5 = bulk_densitie5 * 40\n",
    "        weight6 = bulk_densitie6 * 100\n",
    "        # 假设 ds1 和 ds2 是 xarray 数据集，且 ds2 的坐标需要调整\n",
    "        weight1 = weight1.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        weight2 = weight2.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        weight3 = weight3.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        weight4 = weight4.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        weight5 = weight5.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        weight6 = weight6.interp(y=ds1.y, x=ds1.x, method='nearest')\n",
    "        layer_30 = (ds1*weight1 + ds2*weight2 + ds3*weight3)/(weight1 + weight2 + weight3)\n",
    "        layer_100 = (ds4*weight4 + ds5*weight5)/(weight4 + weight5)\n",
    "        layer_200 = ds6\n",
    "        outdir1 = fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_0-30cm_mean.tif'\n",
    "        outdir2 = fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_30-100cm_mean.tif'\n",
    "        outdir3 = fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_0.08\\{file_dir}\\{file_dir}_100-200cm_mean.tif'\n",
    "        ouput_path = fr'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_0.08\\{file_dir}'\n",
    "        mk_dir(ouput_path)\n",
    "        resample_008(layer_30, outdir1)\n",
    "        resample_008(layer_100, outdir2)\n",
    "        resample_008(layer_200, outdir3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重采样ForestAge数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\202498163741222_BGIForestAgeMPIBGC1.0.0.nc').ForestAge_TC030\n",
    "resample_008(ds, 'G:/PHD_Project/Data/BGIForestAge/BGIForestAge_0.08.nc')\n",
    "xr.open_dataset(r'G:/PHD_Project/Data/BGIForestAge/BGIForestAge_0.08.nc').ForestAge_TC030.plot()\n",
    "xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\202498163741222_BGIForestAgeMPIBGC1.0.0.nc').ForestAge_TC030.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将提取0.08的species数据提取为csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_grid, lat_grid = np.meshgrid(bb.x_bins.values, bb.y_bins.values)\n",
    "df = pd.DataFrame({\n",
    "    'Lon': lon_grid.ravel(),\n",
    "    'Lat': lat_grid.ravel(),\n",
    "    'S': bb.sel(band=1).values.ravel()\n",
    "})\n",
    "df = df.dropna(subset=['S'])\n",
    "df.to_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取每个像元各种指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDTree 提取法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(row, drought_type, drought_intensity, drought_duration,variable_name):\n",
    "    # 找到最近点的索引\n",
    "    dist, idx = tree.query([row['x'], row['y']])\n",
    "    # 根据索引解析lon和lat坐标\n",
    "    lon_idx, lat_idx = np.unravel_index(idx, lon_grid.shape)\n",
    "    \n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    extracted_values = drought_type['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    drought_intensity_values = drought_intensity['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    drought_duration_values = drought_duration['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    # 创建结果列表，过滤掉NaN值\n",
    "    results = []\n",
    "    for t_idx, value in enumerate(extracted_values):\n",
    "        if not np.isnan(value):\n",
    "            result_row = row.copy()\n",
    "            result_row['drought_time'] = drought_type.time.values[t_idx]\n",
    "            result_row[variable_name] = value\n",
    "            result_row['drought_intensity'] = drought_intensity_values[t_idx]\n",
    "            result_row['drought_duration'] = drought_duration_values[t_idx]\n",
    "            results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "species_data = pd.read_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv')\n",
    "# drought_types=['hot_drought_resistance','hot_drought_resilience','normal_drought_resistance', 'normal_drought_resilience']\n",
    "drought_types=['normal_drought_resistance', 'normal_drought_resilience']\n",
    "for drought_types in drought_types:\n",
    "    drought_type = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\{drought_types}.nc')\n",
    "    if drought_types == 'hot_drought_resistance' or drought_types == 'hot_drought_resilience':\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "    else:\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')\n",
    "        \n",
    "    lons = drought_type['lon'].values\n",
    "    lats = drought_type['lat'].values\n",
    "    # 创建KDTree以便快速匹配经纬度\n",
    "    lon_grid, lat_grid = np.meshgrid(lons, lats, indexing='ij')\n",
    "    coordinates = np.array(list(zip(lon_grid.ravel(), lat_grid.ravel())))\n",
    "    tree = KDTree(coordinates)\n",
    "    # 应用提取函数\n",
    "    results = []\n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, drought_type, drought_intensity, drought_duration,drought_types))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.025\\plot_{drought_types}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取气候土壤林岭为csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "def extract_data(row, bio_climate_name):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    # 找到最近点的索引\n",
    "    dist, idx = tree.query([row['Lat'], row['Lon']])\n",
    "    # 根据索引解析lon和lat坐标\n",
    "    lat_idx, lon_idx = np.unravel_index(idx, lon_grid.shape)\n",
    "    results = []\n",
    "    result_row = row.copy()\n",
    "    # 提取林岭\n",
    "    forest_age_data = xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\BGIForestAge_0.08.nc').ForestAge_TC030\n",
    "    forest_age_values = forest_age_data.isel(latitude_bins= lat_idx, longitude_bins=lon_idx).values\n",
    "    result_row['forest_age'] = forest_age_values\n",
    "\n",
    "    # 提取生物气候\n",
    "    world_clim_dir = r\"G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio_extract_0.08\"\n",
    "    world_clim_files = natsorted(os.listdir(world_clim_dir))\n",
    "    for i ,world_clim_file in enumerate(world_clim_files):\n",
    "        world_clim_file_name = os.path.join(world_clim_dir, world_clim_file)\n",
    "        world_clim_data = rxr.open_rasterio(world_clim_file_name, masked=True)\n",
    "        world_clim_values = world_clim_data.isel(band=0, y=lat_idx, x=lon_idx).values\n",
    "        result_row[bio_climate_name[i]] = world_clim_values\n",
    "    \n",
    "    # 提取土壤\n",
    "    soil_grid_path = r\"G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_extract_0.08\"\n",
    "    soil_grid_dirs = os.listdir(soil_grid_path)\n",
    "    for soil_grid_dir in soil_grid_dirs:\n",
    "        soil_grid_file_path = os.path.join(soil_grid_path, soil_grid_dir)\n",
    "        soil_grid_file_names = os.listdir(soil_grid_file_path)\n",
    "        for soil_grid_file_name in soil_grid_file_names:\n",
    "            soil_grid_data = rxr.open_rasterio(os.path.join(soil_grid_file_path, soil_grid_file_name), masked=True)\n",
    "            soil_grid_values = soil_grid_data.isel(band=0, y=lat_idx, x=lon_idx).values\n",
    "            vars_name = soil_grid_file_name.split('.tif')[0]\n",
    "            result_row[vars_name] = soil_grid_values\n",
    "            \n",
    "    results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "model_ds= xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\BGIForestAge_0.08.nc').ForestAge_TC030\n",
    "lats = model_ds['latitude_bins'].values\n",
    "lons = model_ds['longitude_bins'].values\n",
    "lat_grid, lon_grid= np.meshgrid(lats, lons, indexing='ij')\n",
    "coordinates = np.array(list(zip(lat_grid.ravel(), lon_grid.ravel())))\n",
    "tree = KDTree(coordinates)\n",
    "bio_climate = ['Annual Mean Temperature', 'Isothermality', 'Temperature Seasonality', 'Annual Precipitation', 'Precipitation Seasonality',\n",
    "               'Precipitation of Warmest Quarter', 'Precipitation of Coldest Quarter'\n",
    "]\n",
    "source_dir = r\"G:\\PHD_Project\\Plot_Drought\\Global_0.08\"\n",
    "source_files = os.listdir(source_dir)\n",
    "for source_file in tqdm(source_files):\n",
    "    file_name = os.path.join(source_dir, source_file)\n",
    "    species_data = pd.read_csv(file_name)\n",
    "    results = []\n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, bio_climate))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.08_KDTree\\{source_file}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接经纬度查找法提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取抵抗力、恢复力、干旱强度等为csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(row, drought_type, drought_intensity, drought_duration,variable_name):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    extracted_values = drought_type.sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    drought_intensity_values = drought_intensity['ndvi'].sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    drought_duration_values = drought_duration['ndvi'].sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    # 创建结果列表，过滤掉NaN值\n",
    "    results = []\n",
    "    for t_idx, value in enumerate(extracted_values):\n",
    "        if not np.isnan(value):\n",
    "            result_row = row.copy()\n",
    "            result_row['drought_time'] = drought_type.time.values[t_idx]\n",
    "            result_row[variable_name] = value\n",
    "            result_row['drought_intensity'] = drought_intensity_values[t_idx]\n",
    "            result_row['drought_duration'] = drought_duration_values[t_idx]\n",
    "            results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_data = pd.read_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv')\n",
    "drought_types=['hot_drought_resistance','hot_drought_resilience','normal_drought_resistance', 'normal_drought_resilience']\n",
    "for drought_types in drought_types:\n",
    "    drought_type = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\{drought_types}.nc')\n",
    "    if drought_types == 'hot_drought_resistance' or drought_types == 'hot_drought_resilience':\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "    else:\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')\n",
    "    # 应用提取函数\n",
    "    results = []\n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, drought_type, drought_intensity, drought_duration, drought_types))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.08\\plot_{drought_types}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取气候土壤林岭数据为csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "def extract_data(row, bio_climate_name):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    results = []\n",
    "    result_row = row.copy()\n",
    "    # 提取林岭\n",
    "    forest_age_data = xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\BGIForestAge_0.08.nc').ForestAge_TC030\n",
    "    forest_age_values = forest_age_data.sel(latitude_bins=row['Lat'], longitude_bins=row['Lon'], method='nearest').values\n",
    "    result_row['forest_age'] = forest_age_values\n",
    "\n",
    "    # 提取生物气候\n",
    "    world_clim_dir = r\"G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio_0.08\"\n",
    "    world_clim_files = natsorted(os.listdir(world_clim_dir))\n",
    "    for i ,world_clim_file in enumerate(world_clim_files):\n",
    "        world_clim_file_name = os.path.join(world_clim_dir, world_clim_file)\n",
    "        world_clim_data = rxr.open_rasterio(world_clim_file_name, masked=True)\n",
    "        world_clim_values = world_clim_data.sel(y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "        result_row[bio_climate_name[i]] = world_clim_values\n",
    "    \n",
    "    #提取土壤\n",
    "    soil_grid_path = r\"G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_0.08\"\n",
    "    soil_grid_dirs = os.listdir(soil_grid_path)\n",
    "    for soil_grid_dir in soil_grid_dirs:\n",
    "        soil_grid_file_path = os.path.join(soil_grid_path, soil_grid_dir)\n",
    "        soil_grid_file_names = os.listdir(soil_grid_file_path)\n",
    "        for soil_grid_file_name in soil_grid_file_names:\n",
    "            soil_grid_data = rxr.open_rasterio(os.path.join(soil_grid_file_path, soil_grid_file_name), masked=True)\n",
    "            soil_grid_values = soil_grid_data.sel(y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "            vars_name = soil_grid_file_name.split('.tif')[0]\n",
    "            result_row[vars_name] = soil_grid_values\n",
    "    # 创建结果列表，过滤掉NaN值\n",
    "    results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "def extract_data(row, bio_climate_name):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    results = []\n",
    "    result_row = row.copy()\n",
    "    # 提取林岭\n",
    "    forest_age_data = xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\BGIForestAge_0.08.nc').ForestAge_TC030\n",
    "    forest_age_values = forest_age_data.sel(latitude_bins=row['Lat'], longitude_bins=row['Lon'], method='nearest').values\n",
    "    result_row['forest_age'] = forest_age_values\n",
    "\n",
    "    # 提取生物气候\n",
    "    world_clim_dir = r\"G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio_extract_0.08\"\n",
    "    world_clim_files = natsorted(os.listdir(world_clim_dir))\n",
    "    for i ,world_clim_file in enumerate(world_clim_files):\n",
    "        world_clim_file_name = os.path.join(world_clim_dir, world_clim_file)\n",
    "        world_clim_data = rxr.open_rasterio(world_clim_file_name, masked=True)\n",
    "        world_clim_values = world_clim_data.sel(band=1, y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "        result_row[bio_climate_name[i]] = world_clim_values\n",
    "    \n",
    "    # 提取土壤\n",
    "    soil_grid_path = r\"G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_extract_0.08\"\n",
    "    soil_grid_dirs = os.listdir(soil_grid_path)\n",
    "    for soil_grid_dir in soil_grid_dirs:\n",
    "        soil_grid_file_path = os.path.join(soil_grid_path, soil_grid_dir)\n",
    "        soil_grid_file_names = os.listdir(soil_grid_file_path)\n",
    "        for soil_grid_file_name in soil_grid_file_names:\n",
    "            soil_grid_data = rxr.open_rasterio(os.path.join(soil_grid_file_path, soil_grid_file_name), masked=True)\n",
    "            soil_grid_values = soil_grid_data.sel(band=1, y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "            vars_name = soil_grid_file_name.split('.tif')[0]\n",
    "            result_row[vars_name] = soil_grid_values\n",
    "            \n",
    "    results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高效率提取气候土壤林岭数据为csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "def extract_data(row, bio_climate_name, forest_age_data, world_clim_data_list, soil_grid_data_dict):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    results = []\n",
    "    result_row = row.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    # 提取林龄数据\n",
    "    forest_age_values = forest_age_data.sel(latitude_bins=row['Lat'], longitude_bins=row['Lon'], method='nearest').values\n",
    "    result_row['forest_age'] = forest_age_values\n",
    "\n",
    "    # 提取生物气候数据\n",
    "    for i, world_clim_data in enumerate(world_clim_data_list):\n",
    "        world_clim_values = world_clim_data.sel(band=1, y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "        result_row[bio_climate_name[i]] = world_clim_values\n",
    "\n",
    "    # 提取土壤数据\n",
    "    for soil_grid_file_name, soil_grid_data in soil_grid_data_dict.items():\n",
    "        soil_grid_values = soil_grid_data.sel(band=1, y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "        vars_name = soil_grid_file_name.split('.tif')[0]\n",
    "        result_row[vars_name] = soil_grid_values\n",
    "\n",
    "    results.append(result_row)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_climate_name = ['Annual Mean Temperature', 'Mean Diurnal Range', 'Isothermality', 'Temperature Seasonality', 'Max Temperature of Warmest Month',\n",
    "#             'Min Temperature of Coldest Month', 'Temperature Annual Range', 'Mean Temperature of Wettest Quarter', 'Mean Temperature of Driest Quarter',\n",
    "#             'Mean Temperature of Warmest Quarter', 'Mean Temperature of Coldest Quarter', 'Annual Precipitation', 'Precipitation of Wettest Month',\n",
    "#             'Precipitation of Driest Month', 'Precipitation Seasonality ', 'Precipitation of Wettest Quarter', 'Precipitation of Driest Quarter',\n",
    "#             'Precipitation of Warmest Quarter', 'Precipitation of Coldest Quarter'\n",
    "#                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_climate_name = ['Annual Mean Temperature', 'Isothermality', 'Temperature Seasonality', 'Annual Precipitation', 'Precipitation Seasonality',\n",
    "               'Precipitation of Warmest Quarter', 'Precipitation of Coldest Quarter'\n",
    "]\n",
    "source_dir = r\"G:\\PHD_Project\\Plot_Drought\\Global_0.08\"\n",
    "source_files = os.listdir(source_dir)\n",
    "for source_file in tqdm(source_files):\n",
    "    file_name = os.path.join(source_dir, source_file)\n",
    "    species_data = pd.read_csv(file_name)\n",
    "    results = []\n",
    "\n",
    "    # 读取林龄数据\n",
    "    forest_age_data = xr.open_dataset(r'G:\\PHD_Project\\Data\\BGIForestAge\\BGIForestAge_0.08.nc').ForestAge_TC030\n",
    "\n",
    "    # 读取生物气候数据\n",
    "    world_clim_dir = r\"G:\\PHD_Project\\Data\\WorldClim_v2.1\\wc2.1_30s_bio_extract_0.08\"\n",
    "    world_clim_files = natsorted(os.listdir(world_clim_dir))\n",
    "    world_clim_data_list = [rxr.open_rasterio(os.path.join(world_clim_dir, world_clim_file), masked=True) \n",
    "                            for world_clim_file in world_clim_files]\n",
    "\n",
    "    # 读取土壤数据\n",
    "    soil_grid_path = r\"G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_extract_0.08\"\n",
    "    soil_grid_dirs = os.listdir(soil_grid_path)\n",
    "    soil_grid_data_dict = {}  # 用于存储所有土壤数据\n",
    "    for soil_grid_dir in soil_grid_dirs:\n",
    "        soil_grid_file_path = os.path.join(soil_grid_path, soil_grid_dir)\n",
    "        soil_grid_file_names = os.listdir(soil_grid_file_path)\n",
    "        for soil_grid_file_name in soil_grid_file_names:\n",
    "            soil_grid_data = rxr.open_rasterio(os.path.join(soil_grid_file_path, soil_grid_file_name), masked=True)\n",
    "            soil_grid_data_dict[soil_grid_file_name] = soil_grid_data\n",
    "            \n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, bio_climate_name, forest_age_data, world_clim_data_list, soil_grid_data_dict))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.08_quick\\{source_file}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "def extract_data(row, soil_grid_files, soil_grid_data_list):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    results = []\n",
    "    result_row = row.copy()\n",
    "\n",
    "    # 提取土壤数据\n",
    "    for i, soil_grid_data in enumerate(soil_grid_data_list):\n",
    "        soil_grid_values = soil_grid_data.sel(band=1, y=row['Lat'], x=row['Lon'], method='nearest').values\n",
    "        vars_name = soil_grid_files[i].split('.tif')[0]\n",
    "        result_row[vars_name] = soil_grid_values\n",
    "\n",
    "    results.append(result_row)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3895613fbf2942b4b2d35df6b5287da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301d6fc6b4a448b0b6b578d1407bd0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1375750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4130d2b0f44f1a9aa25745f2e3d9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/531406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1842ad47e941649ef1db0c9b86d6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/602779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26914e240d648fb9786ebd8d101814e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/241616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_dir = r\"G:\\PHD_Project\\Plot_Drought\\Global_0.08\"\n",
    "source_files = os.listdir(source_dir)\n",
    "for source_file in tqdm(source_files):\n",
    "    file_name = os.path.join(source_dir, source_file)\n",
    "    species_data = pd.read_csv(file_name)\n",
    "    results = []\n",
    "\n",
    "    # 读取土壤数据\n",
    "    soil_grid_dir = r'G:\\PHD_Project\\Data\\SoilGrid\\SoilGrid_merge_weight_extract_0.08\\nitrogen'\n",
    "    soil_grid_files = os.listdir(soil_grid_dir)\n",
    "    soil_grid_data_list = [rxr.open_rasterio(os.path.join(soil_grid_dir, soil_grid_file), masked=True) \n",
    "                            for soil_grid_file in soil_grid_files]\n",
    "            \n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, soil_grid_files, soil_grid_data_list))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.08_quick\\{source_file}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除某列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = r\"G:\\PHD_Project\\Plot_Drought\\Global_0.08_quick\"\n",
    "source_files = os.listdir(source_dir)\n",
    "for source_file in tqdm(source_files):\n",
    "    file_name = os.path.join(source_dir, source_file)\n",
    "    species_data = pd.read_csv(file_name)\n",
    "    # 删除指定的列\n",
    "    species_data.drop(['nitrogen_0-30cm_mean', 'nitrogen_30-100cm_mean'], axis=1, inplace=True)\n",
    "    # 保存修改后的DataFrame到原文件\n",
    "    species_data.to_csv(file_name, index=False)  # index=False避免写入行索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
