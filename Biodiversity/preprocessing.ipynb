{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_info import *\n",
    "from tools import *\n",
    "from plot import *\n",
    "from ntpath import join\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_root):\n",
    "\n",
    "    datadir = join(data_root, 'GIMMS3g_NDVI')\n",
    "\n",
    "    clean(datadir)\n",
    "    resample_merge(datadir)\n",
    "    monthly_compose(datadir, method='max')\n",
    "    deseason_detrend(datadir)\n",
    "    Month_to_daily(datadir)\n",
    "    HANTS().run(datadir)\n",
    "    growing_season_mask_monthly(datadir)\n",
    "\n",
    "def calculate_growing_season(growing_season_mask):\n",
    "    \"\"\"\n",
    "    计算生长季开始时间、结束时间、长度\n",
    "\n",
    "    \"\"\"\n",
    "    growing_season_start = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "    growing_season_end = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "    growing_season_lenth = xr.full_like(growing_season_mask.astype(float), np.nan)  # 初始化，所有值为NaN\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(growing_season_mask.lat.values):\n",
    "        for lon in growing_season_mask.lon.values:\n",
    "            # 提取单个像元的温度和掩码\n",
    "            pixel_growing_season_mask = growing_season_mask.sel(lat=lat, lon=lon)\n",
    "            \n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_growing_season_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "            \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_growing_season_mask.time) and pixel_growing_season_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    start_time = pixel_growing_season_mask.time[start_idx].values  # 获取生长季开始时间  \n",
    "                    start_month_of_year  = pd.to_datetime(start_time).month\n",
    "                    end_time = pixel_growing_season_mask.time[end_idx - 1].values  # 获取生长季结束时间\n",
    "                    end_month_of_year  = pd.to_datetime(end_time).month\n",
    "                    # 转换为 pandas Timestamp\n",
    "                    start_timestamp = pd.to_datetime(start_time)\n",
    "                    end_timestamp = pd.to_datetime(end_time)\n",
    "                    # 计算月份差异\n",
    "                    length_months = (end_timestamp.year - start_timestamp.year) * 12 + end_timestamp.month - start_timestamp.month + 1\n",
    "                    # length = np.datetime64(end_time) - np.datetime64(start_time)# 获取生长季长度\n",
    "                    # length_days = length.astype('timedelta64[D]').astype(int) + 1  \n",
    "                    growing_season_start.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = start_month_of_year\n",
    "                    growing_season_end.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = end_month_of_year\n",
    "                    growing_season_lenth.loc[{'lat': lat, 'lon': lon, 'time': pixel_growing_season_mask.time[start_idx]}] = length_months\n",
    "\n",
    "                  \n",
    "    growing_season_start.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_start.nc4')\n",
    "    growing_season_end.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_end.nc4')\n",
    "    growing_season_lenth.to_netcdf(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_lenth.nc4')        \n",
    "\n",
    "    return growing_season_start, growing_season_end, growing_season_lenth\n",
    "\n",
    "def drop_consecutive_drought(drought_mask):\n",
    "    \"\"\"\n",
    "    去除两年内连续发生的干旱\n",
    "\n",
    "    \"\"\"\n",
    "    drop_nyear_drought = drought_mask.copy()\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drop_nyear_drought.lat.values):\n",
    "        for lon in drop_nyear_drought.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for i, start_idx in enumerate(region_starts):\n",
    "                    if i + 1 < len(region_starts):\n",
    "                        months_between = region_starts[i+1] - region_starts[i]\n",
    "                        if months_between <=24:\n",
    "                            next_end_idx = region_starts[i+1] +1\n",
    "                            while next_end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[next_end_idx] == 1:\n",
    "                                next_end_idx += 1  # 找到连续区间的结束索引\n",
    "                            region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(next_end_idx)))  \n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time}] = np.nan\n",
    "                                                       \n",
    "    return  drop_nyear_drought \n",
    "\n",
    "def drop_consecutive_all_drought(drought_mask, another_drought_mask):\n",
    "    \"\"\"\n",
    "    去除两年内连续发生的干旱\n",
    "\n",
    "    \"\"\"\n",
    "    drop_nyear_drought = drought_mask.copy()\n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drop_nyear_drought.lat.values):\n",
    "        for lon in drop_nyear_drought.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "            pixel_another_drought_mask = another_drought_mask.sel(lat=lat, lon=lon)\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for i, start_idx in enumerate(region_starts):\n",
    "                    if i + 1 < len(region_starts):\n",
    "                        months_between = region_starts[i+1] - region_starts[i]\n",
    "                        if months_between <=24:\n",
    "                            next_end_idx = region_starts[i+1] +1\n",
    "                            while next_end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[next_end_idx] == 1:\n",
    "                                next_end_idx += 1  # 找到连续区间的结束索引\n",
    "                            region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(next_end_idx)))  \n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time}] = np.nan\n",
    "\n",
    "                    if i < len(region_starts):\n",
    "                        two_years_later = pd.to_datetime(pixel_drought_mask.time[start_idx].values) + pd.DateOffset(years=2) # 干旱开始后的两年\n",
    "                        if two_years_later <= (pixel_another_drought_mask.time[-1].values):        \n",
    "                            two_years_another_drought = pixel_another_drought_mask.sel(time=slice(pixel_drought_mask.time[start_idx].values, two_years_later))\n",
    "                        else:\n",
    "                            two_years_another_drought = pixel_another_drought_mask.sel(time=slice(pixel_drought_mask.time[start_idx].values, pixel_another_drought_mask.time[-1].values))\n",
    "                        if (two_years_another_drought == 1).any():\n",
    "                            drop_nyear_drought.loc[{'lat': lat, 'lon': lon, 'time': two_years_another_drought.time[0]}] = np.nan\n",
    "    return  drop_nyear_drought \n",
    "\n",
    "def statistic_drought_times(drough_mask):\n",
    "    \"\"\"\n",
    "    计算干旱次数\n",
    "\n",
    "    \"\"\"\n",
    "    drought_times = xr.full_like(drough_mask, np.nan)  \n",
    "\n",
    "    # 遍历每个地理位置\n",
    "    for lat in tqdm(drough_mask.lat.values):\n",
    "        for lon in drough_mask.lon.values:\n",
    "            # 提取单个像元的温度和掩码 \n",
    "            pixel_drought_mask = drough_mask.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    region_drought = pixel_drought_mask.isel(time=slice(int(start_idx), int(end_idx)))  \n",
    "                    drought_times.loc[{'lat': lat, 'lon': lon, 'time': region_drought.time[0]}] = 1\n",
    "                                                       \n",
    "    return  drought_times \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Deseason_detrend\\deseason_detrend.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Result\\drought_frequency.nc')\n",
    "# ds1=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc')\n",
    "# ds = xr.open_dataset('E:/PHD_Project/Data/GIMMS3g_NDVI/Resample_merge/ndvi3g_geo_v1_2_2021_0712.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Month_to_daily\\1988.nc4')\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Hants_daily\\2021.nc4')\n",
    "# ds1=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Month_to_daily\\2021.nc4')\n",
    "# xr.open_mfdataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Hants_daily\\*.nc4', concat_dim='time', combine='nested' )\n",
    "# ds=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\growing_season_mask_monthly.nc4')\n",
    "# growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\growing_season_mask_monthly.nc4').ndvi\n",
    "# growing_season_mask.isel(time=12).plot()\n",
    "# growing_season_mask.sel(time=slice('2010-01-01', '2012-01-01')).sel(lon=100, lat=60 , method='nearest').plot()\n",
    "# growing_season_mask.sel(time=slice('2010-01-01', '2013-01-01')).sel(lon=-50, lat=0 , method='nearest').plot()\n",
    "# growing_season_mask.sel(time=slice('1982-01-01', '1986-01-01')).sel(lon=-50, lat=-20 , method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_GIMMS = join(data_root, 'GIMMS3g_NDVI')\n",
    "datadir_SPEI = join(data_root, 'SPEI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生长季开始，结束，长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "growing_season_start, growing_season_end, growing_season_lenth=calculate_growing_season(growing_season_mask)\n",
    "growing_season_start=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_start.nc4')\n",
    "growing_season_end=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_end.nc4')\n",
    "growing_season_lenth=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_statistic\\growing_season_lenth.nc4')\n",
    "def filter_multigrowing_season(ds):\n",
    "    \n",
    "    growing_season_mask = (ds > 0)\n",
    "    season_starts_per_year = growing_season_mask.sum(dim='time', skipna=True)\n",
    "    return ds.where(season_starts_per_year <=1)\n",
    "\n",
    "# 将这些像元在原数据中设置为NaN\n",
    "growing_season_start_new = growing_season_start.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_end_new = growing_season_end.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_lenth_new = growing_season_lenth.groupby('time.year').apply(filter_multigrowing_season)\n",
    "growing_season_start_mean =growing_season_start_new.ndvi.mean(dim='time')\n",
    "growing_season_end_mean =growing_season_end_new.ndvi.mean(dim='time')\n",
    "growing_season_lenth_mean =growing_season_lenth_new.ndvi.mean(dim='time')\n",
    "statistics_2d(growing_season_start_mean)\n",
    "statistics_2d(growing_season_end_mean)\n",
    "statistics_2d(growing_season_lenth_mean)\n",
    "plot_spei2d(growing_season_start_mean, cmap= 'viridis')\n",
    "plot_spei2d(growing_season_end_mean, cmap= 'viridis')\n",
    "plot_spei2d(growing_season_lenth_mean, cmap= 'YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算并统计四种干旱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\normal_drought_times.nc').ndvi\n",
    "extreme_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\extreme_drought_times.nc').ndvi\n",
    "normal_hot_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\normal_hot_drought_times.nc').ndvi\n",
    "extreme_hot_drought_times=xr.open_dataset(r'E:\\PHD_Project\\Results\\Drought_types\\extreme_hot_drought_times.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_times_sum = normal_drought_times.sum(dim='time')\n",
    "extreme_drought_times_sum = extreme_drought_times.sum(dim='time')\n",
    "normal_hot_drought_times_sum = normal_hot_drought_times.sum(dim='time')\n",
    "extreme_hot_drought_times_sum = extreme_hot_drought_times.sum(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(normal_drought_times_sum.where(normal_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(extreme_drought_times_sum.where(extreme_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(normal_hot_drought_times_sum.where(normal_hot_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_2d(extreme_hot_drought_times_sum.where(extreme_hot_drought_times_sum>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(normal_drought_times_sum.where(normal_drought_times_sum>0), cmap='hot', vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(extreme_drought_times_sum.where(extreme_drought_times_sum>0), cmap='hot', vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(normal_hot_drought_times_sum.where(normal_hot_drought_times_sum>0), cmap='hot', vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(extreme_hot_drought_times_sum.where(extreme_hot_drought_times_sum>0), cmap='hot', vmax =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc').spei\n",
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "tmp=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Source\\cru_ts4.07.1901.2022.tmp.dat.nc').tmp\n",
    "hot_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Hot_drought_tmp\\hot_mask.nc').tmp\n",
    "# 按月重采样到每月开始, 将时间对齐\n",
    "spei = spei.resample(time='MS').mean()  # 'MS'表示每月的开始，mean()是一种聚合方法，你可以根据需要选择合适的聚合方法\n",
    "growing_season_mask = growing_season_mask.resample(time='MS').mean()\n",
    "# 截取ndvi同等时间段\n",
    "tmp=tmp.resample(time='MS').mean().sel(time=growing_season_mask.time)\n",
    "spei = spei.sel(time=growing_season_mask.time)\n",
    "#筛选干旱并提取生长季干旱\n",
    "normal_hot_drought_mask = growing_season_mask.where((spei < -0.5) & (spei > -1.5) & (hot_mask == 1))\n",
    "extreme_hot_drought_mask = growing_season_mask.where((spei <= -1.5) & (hot_mask == 1))\n",
    "normal_drought_mask = growing_season_mask.where((spei < -0.5) & (spei > -1.5) & (normal_hot_drought_mask != 1))\n",
    "extreme_drought_mask = growing_season_mask.where((spei <= -1.5) & (extreme_hot_drought_mask != 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_drought(drought_types, out_fname_list):\n",
    "\n",
    "    results_droped_drought=[]\n",
    "    results_drought_times=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "\n",
    "        droped_drought=drop_consecutive_drought(drought_types[i])\n",
    "        \n",
    "        drought_times=statistic_drought_times(droped_drought)\n",
    "\n",
    "        results_droped_drought.append(droped_drought)\n",
    "        results_drought_times.append(drought_times)\n",
    "\n",
    "        droped_drought.to_netcdf(rf'E:\\PHD_Project\\Results\\Drought_types\\{out_fname_list[i]}_droped.nc') \n",
    "        drought_times.to_netcdf(rf'E:\\PHD_Project\\Results\\Drought_types\\{out_fname_list[i]}_times.nc') \n",
    "    \n",
    "    return results_droped_drought, results_drought_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_hot_drought_mask, extreme_hot_drought_mask, normal_drought_mask, extreme_drought_mask]\n",
    "out_fname_list=['normal_hot_drought', 'extreme_hot_drought', 'normal_drought', 'extreme_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_drought, drought_times=caculate_drought(drought_types, out_fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据干旱强度、划分干旱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_one_month_slight_drought(spei):\n",
    "\n",
    "    condition = (spei<= -0.5) & (spei>= -0.55)\n",
    "\n",
    "    # 遍历每个空间位置\n",
    "    for lat in tqdm(spei.lat, desc='Processing Latitude'):\n",
    "        for lon in spei.lon:\n",
    "            # 提取该位置的时间序列\n",
    "            pixel_spei = condition.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_spei == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_spei.time) and pixel_spei[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    if end_idx - start_idx <= 1:\n",
    "                        region_spei = pixel_spei.isel(time=slice(int(start_idx), int(end_idx))) \n",
    "                    \n",
    "                        spei.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = np.nan\n",
    "                    \n",
    "    return spei\n",
    "\n",
    "def caculate_new_drought(drought_types, out_fname_list):\n",
    "\n",
    "    results_droped_drought=[]\n",
    "    results_drought_times=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "        if i == 0:\n",
    "            droped_drought=drop_consecutive_all_drought(drought_types[i], drought_types[i+1])\n",
    "            drought_times=statistic_drought_times(droped_drought)\n",
    "            results_droped_drought.append(droped_drought)\n",
    "            results_drought_times.append(drought_times)\n",
    "        if i == 1:\n",
    "            droped_drought=drop_consecutive_all_drought(drought_types[i], drought_types[i-1])\n",
    "            drought_times=statistic_drought_times(droped_drought)\n",
    "            results_droped_drought.append(droped_drought)\n",
    "            results_drought_times.append(drought_times)\n",
    "            \n",
    "        droped_drought.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_types\\{out_fname_list[i]}_droped.nc') \n",
    "        drought_times.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_types\\{out_fname_list[i]}_times.nc') \n",
    "    \n",
    "    return results_droped_drought, results_drought_times\n",
    "\n",
    "def drought_intensity_duration(drought_mask, spei ):\n",
    "\n",
    "   \n",
    "    drought_intensity = xr.full_like(drought_mask, np.nan) \n",
    "    drought_duration = xr.full_like(drought_mask, np.nan) \n",
    "\n",
    "    # 遍历每个空间位置\n",
    "    for lat in tqdm(drought_mask.lat, desc='Processing Latitude'):\n",
    "        for lon in drought_mask.lon:\n",
    "            # 提取该位置的时间序列\n",
    "            pixel_drought_mask = drought_mask.sel(lat=lat, lon=lon)\n",
    "            pixel_spei = spei.sel(lat=lat, lon=lon)\n",
    "\n",
    "            # 计算连续为 1 的区间的索引\n",
    "            region_indices = np.where(pixel_drought_mask == 1)[0]  # 获取为 1 的位置索引\n",
    "            if len(region_indices) > 0:\n",
    "                region_starts = [region_indices[0]]  # 连续区间的起始索引\n",
    "                for i in range(1, len(region_indices)):\n",
    "                    if region_indices[i] != region_indices[i-1] + 1:  # 如果不连续，则记录新的起始索引\n",
    "                        region_starts.append(region_indices[i])\n",
    "\n",
    "                \n",
    "                for start_idx in region_starts:\n",
    "                    end_idx = start_idx + 1\n",
    "                    while end_idx < len(pixel_drought_mask.time) and pixel_drought_mask[end_idx] == 1:\n",
    "                        end_idx += 1  # 找到连续区间的结束索引\n",
    "                    region_spei = pixel_spei.isel(time=slice(int(start_idx), int(end_idx)))  \n",
    "                    result_drought_intensity = -(region_spei.sum())\n",
    "                    result_drought_duration = end_idx - start_idx + 1\n",
    "                    drought_intensity.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = result_drought_intensity\n",
    "                    drought_duration.loc[{'lat': lat, 'lon': lon, 'time': region_spei.time[0]}] = result_drought_duration\n",
    "\n",
    "    return drought_intensity, drought_duration\n",
    "\n",
    "def caculate_intensity_durantion(drought_types, out_fname_list ,spei):\n",
    "\n",
    "    results_intensity=[]\n",
    "    results_duration=[]\n",
    "\n",
    "    for i in tqdm(range(len(drought_types))):\n",
    "\n",
    "\n",
    "        intensity, duration= drought_intensity_duration(drought_types[i], spei)\n",
    "\n",
    "        results_intensity.append(intensity)\n",
    "        results_duration.append(duration)\n",
    "\n",
    "        intensity.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\{out_fname_list[i]}_intensity.nc') \n",
    "        duration.to_netcdf(rf'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\{out_fname_list[i]}_duration.nc') \n",
    "    \n",
    "    return results_intensity, results_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_spei= drop_one_month_slight_drought(spei)\n",
    "droped_spei.to_netcdf(rf'E:\\PHD_Project\\Data\\SPEI\\Result\\droped_spei.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Source\\spei03.nc').spei\n",
    "droped_spei=xr.open_dataset(r'E:\\PHD_Project\\Data\\SPEI\\Result\\droped_spei.nc').spei\n",
    "growing_season_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\GIMMS3g_NDVI\\Growing_season_mask_monthly\\Growing_season_mask_monthly_leftrightclear.nc4').ndvi\n",
    "tmp=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Source\\cru_ts4.07.1901.2022.tmp.dat.nc').tmp\n",
    "hot_mask=xr.open_dataset(r'E:\\PHD_Project\\Data\\CRU\\Hot_drought_tmp\\hot_mask.nc').tmp\n",
    "# 按月重采样到每月开始, 将时间对齐\n",
    "spei = spei.resample(time='MS').mean()  # 'MS'表示每月的开始，mean()是一种聚合方法，你可以根据需要选择合适的聚合方法\n",
    "growing_season_mask = growing_season_mask.resample(time='MS').mean()\n",
    "# 截取ndvi同等时间段\n",
    "tmp=tmp.resample(time='MS').mean().sel(time=growing_season_mask.time)\n",
    "spei = spei.sel(time=growing_season_mask.time)\n",
    "#筛选干旱并提取生长季干旱\n",
    "hot_drought_mask = growing_season_mask.where((droped_spei < -0.5) & (hot_mask == 1))\n",
    "normal_drought_mask = growing_season_mask.where((droped_spei < -0.5) & (hot_drought_mask != 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_drought_mask, hot_drought_mask]\n",
    "out_fname_list=['normal_drought', 'hot_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droped_drought, drought_times=caculate_new_drought(drought_types, out_fname_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_drought_droped=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_types\\normal_drought_droped.nc').ndvi\n",
    "hot_drought_droped=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_types\\hot_drought_droped.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d((drought_times[0].sum(dim= 'time').where(drought_times[0].sum(dim= 'time')>0)), cmap= global_cmap_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spei2d(drought_times[1].sum(dim= 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_types=[normal_drought_droped, hot_drought_droped]\n",
    "out_fname_list=['normal_drought', 'hot_drought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_intensity, results_duration=caculate_intensity_durantion(drought_types, out_fname_list, spei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_intensity=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\hot_drought_intensity.nc').ndvi\n",
    "hot_drought_duration=xr.open_dataset(r'E:\\PHD_Project\\New_results\\Drought_intensity_duration\\hot_drought_duration.nc').ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_intensity.mean(dim= 'time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_drought_duration.mean(dim= 'time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique((hot_drought_intensity.sel(time=slice('1982-01-01', '2022-01-01')).sel(lon=-50, lat=-20 , method='nearest')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取相应像元的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot_drought_duration=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\hot_drought_duration.nc').ndvi\n",
    "# hot_drought_intensity=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\hot_drought_intensity.nc').ndvi\n",
    "normal_drought_duration=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\normal_drought_duration.nc').ndvi\n",
    "normal_drought_intensity=xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration\\normal_drought_intensity.nc').ndvi\n",
    "standard_ds = xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\hot_drought_resilience.nc').ndvi\n",
    "# 获取基准数据的坐标\n",
    "target_coords = standard_ds.drop_vars('month').coords\n",
    "# 重采样到0.08\n",
    "# hot_drought_duration = hot_drought_duration.interp(coords=target_coords, method='nearest')\n",
    "# hot_drought_intensity = hot_drought_intensity.interp(coords=target_coords, method='nearest')\n",
    "normal_drought_duration = normal_drought_duration.interp(coords=target_coords, method='nearest')\n",
    "normal_drought_intensity = normal_drought_intensity.interp(coords=target_coords, method='nearest')\n",
    "# hot_drought_duration = hot_drought_duration.astype('float32')\n",
    "# hot_drought_intensity = hot_drought_intensity.astype('float32')\n",
    "normal_drought_duration = normal_drought_duration.astype('float32')\n",
    "normal_drought_intensity = normal_drought_intensity.astype('float32')\n",
    "# hot_drought_duration.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "# hot_drought_intensity.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "normal_drought_duration.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "normal_drought_intensity.to_netcdf(r'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重采样species为0.08度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_raster = rxr.open_rasterio(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\S_mean_raster.tif')\n",
    "species_raster = xr.where(species_raster == -3.39999995e+38, np.nan, species_raster)\n",
    "target_ds= xr.open_dataset(r'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\normal_drought_resilience.nc').ndvi\n",
    "target_lon = np.append(target_ds.lon.values,target_ds.lon.values[-1]+0.08)-0.04\n",
    "target_lat = np.append(target_ds.lat.values, target_ds.lat.values[-1]-0.08)+0.04\n",
    "# 对纬度进行分组和聚合\n",
    "aa = species_raster.groupby_bins(\"x\", bins=target_lon, labels=target_ds.lon.values).mean(skipna = True)\n",
    "bb= aa.groupby_bins(\"y\", bins=target_lat[::-1], labels=target_ds.lat.values[::-1]).mean(skipna = True)\n",
    "bb.rio.set_spatial_dims(x_dim='x_bins', y_dim='y_bins', inplace=True)\n",
    "bb.rio.write_nodata(np.nan, inplace=True)\n",
    "bb.rio.nodata\n",
    "bb.rio.to_raster(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_grid, lat_grid = np.meshgrid(bb.x_bins.values, bb.y_bins.values)\n",
    "df = pd.DataFrame({\n",
    "    'Lon': lon_grid.ravel(),\n",
    "    'Lat': lat_grid.ravel(),\n",
    "    'S': bb.sel(band=1).values.ravel()\n",
    "})\n",
    "df = df.dropna(subset=['S'])\n",
    "df.to_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取每个像元各种指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDTree 提取法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(row, drought_type, drought_intensity, drought_duration,variable_name):\n",
    "    # 找到最近点的索引\n",
    "    dist, idx = tree.query([row['x'], row['y']])\n",
    "    # 根据索引解析lon和lat坐标\n",
    "    lon_idx, lat_idx = np.unravel_index(idx, lon_grid.shape)\n",
    "    \n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    extracted_values = drought_type['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    drought_intensity_values = drought_intensity['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    drought_duration_values = drought_duration['ndvi'].isel(lat=lat_idx, lon=lon_idx).values\n",
    "    # 创建结果列表，过滤掉NaN值\n",
    "    results = []\n",
    "    for t_idx, value in enumerate(extracted_values):\n",
    "        if not np.isnan(value):\n",
    "            result_row = row.copy()\n",
    "            result_row['drought_time'] = drought_type.time.values[t_idx]\n",
    "            result_row[variable_name] = value\n",
    "            result_row['drought_intensity'] = drought_intensity_values[t_idx]\n",
    "            result_row['drought_duration'] = drought_duration_values[t_idx]\n",
    "            results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "species_data = pd.read_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv')\n",
    "# drought_types=['hot_drought_resistance','hot_drought_resilience','normal_drought_resistance', 'normal_drought_resilience']\n",
    "drought_types=['normal_drought_resistance', 'normal_drought_resilience']\n",
    "for drought_types in drought_types:\n",
    "    drought_type = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\{drought_types}.nc')\n",
    "    if drought_types == 'hot_drought_resistance' or drought_types == 'hot_drought_resilience':\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "    else:\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')\n",
    "        \n",
    "    lons = drought_type['lon'].values\n",
    "    lats = drought_type['lat'].values\n",
    "    # 创建KDTree以便快速匹配经纬度\n",
    "    lon_grid, lat_grid = np.meshgrid(lons, lats, indexing='ij')\n",
    "    coordinates = np.array(list(zip(lon_grid.ravel(), lat_grid.ravel())))\n",
    "    tree = KDTree(coordinates)\n",
    "    # 应用提取函数\n",
    "    results = []\n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, drought_type, drought_intensity, drought_duration,drought_types))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.025\\plot_{drought_types}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接经纬度查找法提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(row, drought_type, drought_intensity, drought_duration,variable_name):\n",
    "    # 提取相应格点在不同时间下的变量值\n",
    "    extracted_values = drought_type['ndvi'].sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    drought_intensity_values = drought_intensity['ndvi'].sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    drought_duration_values = drought_duration['ndvi'].sel(lat=row['Lat'], lon=row['Lon'], method='nearest').values\n",
    "    # 创建结果列表，过滤掉NaN值\n",
    "    results = []\n",
    "    for t_idx, value in enumerate(extracted_values):\n",
    "        if not np.isnan(value):\n",
    "            result_row = row.copy()\n",
    "            result_row['drought_time'] = drought_type.time.values[t_idx]\n",
    "            result_row[variable_name] = value\n",
    "            result_row['drought_intensity'] = drought_intensity_values[t_idx]\n",
    "            result_row['drought_duration'] = drought_duration_values[t_idx]\n",
    "            results.append(result_row)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a1b1db9da74e0ab3f9f0a57308bea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1110323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576f7f8e58fe48b6bc3cbc94e6750060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1110323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e7d86db2654868a9ad7d81a3a53e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1110323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6193f8f08bea47ca8fbaa0b976d860c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1110323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "species_data = pd.read_csv(r'F:\\BaiduSyncdisk\\Data\\Global Map of Local Tree Species Richness per hectare (geoTiff, ~3km resolution)\\global_0.08.csv')\n",
    "drought_types=['hot_drought_resistance','hot_drought_resilience','normal_drought_resistance', 'normal_drought_resilience']\n",
    "for drought_types in drought_types:\n",
    "    drought_type = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Resistance_resilience_0.08\\{drought_types}.nc')\n",
    "    if drought_types == 'hot_drought_resistance' or drought_types == 'hot_drought_resilience':\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\hot_drought_intensity_0.08.nc')\n",
    "    else:\n",
    "        drought_duration = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_duration_0.08.nc')\n",
    "        drought_intensity = xr.open_dataset(rf'G:\\PHD_Project\\2_types_results\\Drought_intensity_duration_0.08\\normal_drought_intensity_0.08.nc')\n",
    "    # 应用提取函数\n",
    "    results = []\n",
    "    for j, row in tqdm(species_data.iterrows(), total=len(species_data)):\n",
    "        results.extend(extract_data(row, drought_type, drought_intensity, drought_duration, drought_types))\n",
    "    # 将结果转化为DataFrame\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(rf'G:\\PHD_Project\\Plot_Drought\\Global_0.08\\plot_{drought_types}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
